{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started with Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models and ouput parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x11aad46a0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11aad7610> root_client=<openai.OpenAI object at 0x11aa47e20> root_async_client=<openai.AsyncOpenAI object at 0x11aad4490> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence that focuses on creating new content or data that is similar to what it has been trained on. This type of AI uses machine learning models, particularly deep learning techniques, to generate text, images, music, and other forms of media. The most common architectures used in generative AI include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer models.\\n\\n1. **Generative Adversarial Networks (GANs):** GANs consist of two neural networks, a generator and a discriminator, that are trained simultaneously. The generator creates new data instances, while the discriminator evaluates them. The goal is for the generator to produce data that is indistinguishable from real data.\\n\\n2. **Variational Autoencoders (VAEs):** VAEs are a type of autoencoder that learn to encode and decode data in a way that the encoded representations are distributed according to a probability distribution. This allows them to generate new data by sampling from this distribution.\\n\\n3. **Transformers:** These are a type of model architecture known for their effectiveness in natural language processing tasks. Models like GPT (Generative Pre-trained Transformer) use transformers to generate human-like text based on input prompts.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n- **Text Generation:** Creating articles, poetry, or dialogue in chatbots.\\n- **Image Generation:** Producing realistic images, art, or design ideas.\\n- **Music and Audio Generation:** Composing music or generating sound effects.\\n- **Game Content Creation:** Designing levels, characters, or storylines.\\n- **Data Augmentation:** Enhancing datasets for training other machine learning models.\\n\\nGenerative AI is increasingly used in industries such as entertainment, healthcare, and marketing to automate creative processes and generate novel solutions. However, it also raises ethical considerations regarding authenticity, copyright, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 388, 'prompt_tokens': 13, 'total_tokens': 401, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None} id='run-affb3789-4b14-48ae-8f65-c9f9a5932300-0' usage_metadata={'input_tokens': 13, 'output_tokens': 388, 'total_tokens': 401, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform developed by LangChain, designed to optimize the development of applications that utilize large language models (LLMs). It focuses on assisting developers in evaluating, testing, and debugging their language model applications. Langsmith provides a suite of tools and features that help in tracking and monitoring application performance, understanding model outputs, and iterating quickly on improvements. It is particularly useful for developers looking to streamline their workflow when building complex applications that rely on LLMs, ensuring that these applications are robust, efficient, and effective in meeting their intended use cases.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 33, 'total_tokens': 145, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None} id='run-47f4e12b-d209-41ed-9fff-0a12bbbbc121-0' usage_metadata={'input_tokens': 33, 'output_tokens': 112, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform developed by LangChain that provides tools for debugging, testing, and monitoring applications built using large language models (LLMs). It is designed to enhance the development and deployment process of LLM-based applications by offering features that help developers understand model behavior, identify issues, and ensure the reliability and accuracy of their models.\n",
      "\n",
      "Key features of LangSmith include:\n",
      "\n",
      "1. **Debugging**: Allows developers to trace and analyze the interactions between their applications and the language models, helping to pinpoint where and why issues occur.\n",
      "\n",
      "2. **Testing**: Enables the creation and execution of test cases to validate the performance and accuracy of the models under various scenarios.\n",
      "\n",
      "3. **Monitoring**: Provides tools for tracking the ongoing performance of language models in production, helping to maintain the quality and efficiency of the applications over time.\n",
      "\n",
      "LangSmith is part of the broader trend of developing infrastructure and tools to support the growing use of LLMs in various applications, ensuring they can be deployed effectively and reliably at scale.\n"
     ]
    }
   ],
   "source": [
    "## strout Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
